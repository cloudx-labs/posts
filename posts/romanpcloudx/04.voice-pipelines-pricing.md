---
title: How Much Does It Really Cost to Run a Voice-AI Agent at Scale?
published: true
description: 'A step-by-step cost breakdownâ€”LiveKit, Deepgram, GPT-4.1 mini, ElevenLabs vs Cartesia, Twilio vs Telnyxâ€”plus tactics to slash the bill when you outgrow every public pricing tier.'
tags: 'ai, voice, cost, analysis'
series: Working with Voice AI Agents
cover_image: ./assets/cover_costs.png
id: 2506635
---

## 1) Why Voice Automation Is Worth Investigating (Even If Youâ€™re Not Replacing Humans)

Voice automation has made significant progress in recent years, powered by improvements in transcription, real-time audio routing, and large language models. What was once a clunky, robotic experience is now capable of holding fluent, natural-sounding conversations with real peopleâ€”across a variety of use cases.

This doesnâ€™t mean weâ€™re replacing human agents. Quite the opposite: automation lets us offload the *repetitive, high-frequency, low-complexity tasks* that tend to burn out human teams, and instead reserve human attention for edge cases, escalations, and creative problem solving.

Whether you're handling inbound customer service, qualifying outbound leads, or proactively following up on time-sensitive actions, a well-orchestrated voice-AI pipeline can free up valuable resourcesâ€”*if the economics make sense*.

That last part is key. Many developers assume that using AI to automate voice interactions is inherently cost-effective. But is it really cheaper than staffing a team? How much do you actually pay per call once you add up every component: speech recognition, synthesis, telephony, model inference, and orchestration?

This article takes a grounded approach to that question. We'll break down a full-stack voice-AI systemâ€”from SIP trunk to final responseâ€”and price each piece out based on real-world usage. To make it concrete, we'll walk through a common use case: outbound phone calls of around 3 minutes in duration. But the same framework applies to inbound routing, reminders, surveys, or any other automated voice interaction.

Letâ€™s dig into how it all connectsâ€”and what it really costs to make it work at scale.

## 2) System Architecture: How a Voice-AI Pipeline Works End-to-End

Before jumping into costs, itâ€™s important to understand how the system is architected. At a high level, a voice-based AI interaction consists of several components working together in real time to process speech, generate responses, and keep the conversation flowing naturally.

Hereâ€™s a simplified view of the architecture:

Caller (PSTN or SIP)
â¬‡ï¸
SIP Trunk (Twilio or Telnyx)
â¬‡ï¸
LiveKit (Voice orchestration & media routing)
â¬‡ï¸
Speech-to-Text (Deepgram)
â¬‡ï¸
Language Model (OpenAI GPT-4.1 mini)
â¬‡ï¸
Text-to-Speech (ElevenLabs or Cartesia)
â¬‡ï¸
LiveKit (returns audio back)
â¬‡ï¸
Caller

Each component has a distinct role:

- **SIP Trunk (Twilio or Telnyx):** Bridges public phone lines to our backend system.
- **LiveKit:** Manages the real-time audio streams and orchestrates audio I/O between services.
- **Deepgram:** Transcribes what the user says into text.
- **GPT-4.1 mini:** Interprets the message and generates a textual response.
- **Text-to-Speech (TTS):** Converts the AI response into natural-sounding speech.
- **LiveKit (again):** Sends the generated audio back to the caller, closing the loop.

If you're interested in building this kind of setup yourself, Iâ€™ve written a few posts on setting up each component individually (from SIP trunking to LiveKit integration). You can check those out here: **[https://dev.to/roman_piacquadio/series/31126]**.

In the next section, weâ€™ll define the assumptions behind our usage model so we can start assigning real-world costs to each of these layers.

## 3) Baseline Assumptions for Cost Estimation

To make the cost analysis meaningful, we need a realistic usage scenario. Weâ€™ll base our calculations on the following assumptions, which simulate a small team operating at steady scale:

### ğŸ“ Call Volume

- Each automated call lasts **3 minutes**.
- The AI system handles **100 calls per day**, simulating the workload of one full-time agent.
- We simulate **10 AI agents**, running **22 business days per month**.
- That results in **22,000 calls per month**, totaling **66,000 minutes of audio**.

### ğŸ—£ï¸ Talk Time Distribution

In a natural two-way conversation, only one party speaks at a time. For simplicity:

- The **AI speaks for ~50%** of the time â†’ **33,000 minutes of TTS**.
- The **caller (human)** speaks for the other 50% â†’ **33,000 minutes of STT**.

This split is a reasonable average for structured interactions such as confirmations, reminders, qualification flows, or outbound follow-ups.

### ğŸ¤– Model and Service Selection

We picked tools that balance **quality**, **latency**, and **cost-effectiveness** for production-level use:

- **LiveKit**: to orchestrate real-time audio and SIP integration.
- **Deepgram Nova-2 (Enterprise)**: for fast, accurate streaming transcription with low per-minute cost.
- **GPT-4.1 mini**: a lightweight, affordable OpenAI model that still delivers strong reasoning and fluency.
- **Text-to-Speech**:
  - **ElevenLabs (Business plan)**: premium voices with emotional range and expressiveness.
  - **Cartesia (Scale plan)**: lower-cost alternative for simpler use cases.
- **SIP Trunking**:
  - **Twilio**: simple and widely used.
  - **Telnyx**: cost-competitive with flexible routing.

This setup lets us explore the full range of pricing scenariosâ€”from economy stacks to premium voice experiencesâ€”while keeping the core system consistent.

## 4) LiveKit â€” Orchestrating the Audio Layer

At the center of our voice pipeline is **LiveKit**, which handles real-time audio routing between the SIP trunk, transcription, TTS, and back to the caller. Itâ€™s the glue that makes low-latency, bidirectional communication possible.

LiveKit offers a generous **Scale Plan** designed for production workloads:

- **Base cost:** $500/month
- **Includes:** 45,000 minutes of usage
- **Overage rate:** $0.003 per additional minute

### ğŸ”¢ Usage Breakdown

With 22,000 calls per month at 3 minutes each, we consume:

- **66,000 total minutes** of LiveKit usage (audio flowing in and out).
- We exceed the planâ€™s included minutes by **21,000 minutes**.
- Overage cost: 21,000 Ã— $0.003 = **$63**

### ğŸ’° Total Monthly Cost for LiveKit

- Base plan: $500
- Overage: $63
- **Total: $563/month**

### ğŸ§® Cost per Unit

| Metric         | Value             |
|----------------|-------------------|
| **Per call**   | $563 Ã· 22,000 = **$0.0256** |
| **Per hour**   | 20 calls/hour â†’ 20 Ã— $0.0256 = **$0.512** |

LiveKitâ€™s pricing scales linearly with usage and is well-suited for handling concurrent calls without needing to manage media servers manually.

> Pricing based on public rates as of **May 2025**.

## 5) Speech-to-Text â€” Transcribing the Human Side with Deepgram

To understand what the caller says, we need fast and accurate transcription. For this, we use **Deepgram**, a popular speech-to-text (STT) provider known for real-time streaming, multilingual support, and competitive enterprise pricing.

We selected the **Nova-2 model (Enterprise tier)** for its balance of speed, accuracy, and affordability.

### ğŸ§ Why Streaming Matters

In a voice AI pipeline, latency is critical. Transcription must happen as the user speaksâ€”not after theyâ€™ve finishedâ€”so the AI can respond naturally in near real-time.

Streaming STT allows:

- Lower response times (smoother dialogue)
- Efficient token handling for the language model
- Better support for interruptions and barge-in behavior

Deepgramâ€™s Nova-2 model supports all of this out of the box.

### ğŸ’° Enterprise Pricing (Nova-2)

- **Rate:** $0.0047 per minute (Enterprise tier, streaming)
- **Applicable usage:** Only transcribing the **human side** of the call (50% of total time)
- **Monthly usage:** 22,000 calls Ã— 1.5 min (caller talk time) = **33,000 minutes**

### ğŸ§® Cost Breakdown

| Metric         | Value             |
|----------------|-------------------|
| **Per call**   | 1.5 min Ã— $0.0047 = **$0.00705** |
| **Per hour**   | 20 calls/hour â†’ 20 Ã— $0.00705 = **$0.141** |
| **Total per month (10 agents)**  | 33,000 min Ã— $0.0047 = **$155.10** |

This STT layer is one of the more affordable components of the pipeline, thanks to Deepgramâ€™s usage-based pricing and efficient streaming infrastructure.

> Pricing based on public Enterprise rates as of **May 2025**.

## 6) Language Model â€” Token Costs with GPT-4.1 mini

The core of any conversational AI system is the language model that generates responses. In our setup, we use **OpenAIâ€™s GPT-4.1 mini**, which offers a great trade-off between intelligence, latency, and price.

Unlike flat-rate pricing, token billing in GPT models varies depending on:

- **Input tokens** (the prompt + conversation history)
- **Output tokens** (the generated reply)
- Whether input tokens are **cached** (like a static system prompt) or **non-cached**

Letâ€™s break that down.

---

### ğŸ“¥ Input Tokens

Each user message builds on previous context. So as the conversation progresses, the number of input tokens increases with every new request.

For a 3-minute call with **6 back-and-forth exchanges**, we estimate:

- **System prompt:** ~2,000 tokens (sent with every request, but cacheable)
- **Conversation context:** grows each turn (averaging 975 tokens total)
- **Total input tokens per call:**
  - **Cached input:** 6 Ã— 2,000 = 12,000 tokens
  - **Non-cached input:** ~975 tokens

---

### ğŸ“¤ Output Tokens

- The model responds 6 times (one per turn), with ~35 tokens per reply
- **Total output tokens per call:** ~210 tokens

---

### ğŸ’° GPT-4.1 mini Pricing (May 2025)

| Token Type       | Rate per million | Per-token cost      |
|------------------|------------------|----------------------|
| Cached input     | $0.10 / 1M       | $0.00000010          |
| Regular input     | $0.40 / 1M       | $0.00000040          |
| Output           | $1.60 / 1M       | $0.00000160          |

---

### ğŸ§® Cost Breakdown (Per Call)

| Token Type     | Tokens | Rate            | Cost         |
|----------------|--------|------------------|--------------|
| Cached input   | 12,000 | $0.10 / 1M       | $0.00120     |
| Non-cached input | 975    | $0.40 / 1M       | $0.00039     |
| Output         | 210    | $1.60 / 1M       | $0.000336    |
| **Total**      | â€”      | â€”                | **$0.001926** |

---

### ğŸ“Š Aggregate Costs

| Metric         | Value                  |
|----------------|------------------------|
| **Per call**   | $0.001926              |
| **Per hour**   | 20 Ã— $0.001926 = **$0.0385** |
| **Total per month (10 agents)**  | 22,000 Ã— $0.001926 = **$42.37** |

---

GPT-4.1 miniâ€™s pricing structure rewards careful prompt engineering and context management. While the per-call cost is low, the input token growth curve makes it important to minimize unnecessary repetition in multi-turn conversations (e.g. trimming old exchanges or summarizing history).

> Pricing based on OpenAIâ€™s GPT-4.1 mini public rates as of **May 2025**.

## 7) Text-to-Speech â€” Choosing Between ElevenLabs and Cartesia

For the AI to respond naturally, we need to convert the modelâ€™s text output into high-quality speech. In our analysis, we compared two leading **Text-to-Speech (TTS)** providers: **ElevenLabs** and **Cartesia**.

Both platforms deliver excellent results:

- ğŸ—£ï¸ **Multilingual support**
- ğŸ­ **Voice cloning capabilities**
- âš¡ **Optimized for low-latency streaming**

The key differences lie in pricing and voice variety.

### ğŸ§¬ ElevenLabs (Business Plan)

- **Extensive voice library**, including highly expressive and emotional voices.
- Well-suited for customer-facing conversations where tone and nuance matter.
- Plan includes **22,000 minutes** for **$1,320/month**.
- **Overage minutes** cost $0.06/min.

We need **33,000 minutes** per month (AI speaks ~50% of every call):

- Base: $1,320  
- Overage: 11,000 Ã— $0.06 = $660  
- **Total: $1,980/month**

### ğŸ§ª Cartesia (Scale Plan)

- Smaller voice library, but **still multilingual and highly intelligible**.
- More cost-effective for less expressive use cases.
- Estimated cost: **$0.0299/min** under the Scale plan.

Monthly cost for 33,000 minutes:

- 33,000 Ã— $0.0299 â‰ˆ **$986.70/month**

---

### ğŸ§® Cost Comparison

| Provider     | Rate           | Monthly Cost | Per Call | Per Hour |
|--------------|----------------|--------------|----------|-----------|
| **ElevenLabs** | $1,980/month (blended) | $1,980      | $0.09    | $1.80     |
| **Cartesia**   | $0.0299/min            | $986.70     | $0.0449  | $0.897    |

---

### ğŸ¯ Which One Should You Use?

- Choose **ElevenLabs** if:
  - You want **high voice fidelity**, emotional range, or public-facing use.
  - You care about building brand consistency with **custom voices**.

- Choose **Cartesia** if:
  - Youâ€™re optimizing for **cost and speed**.
  - Expressiveness is less critical (e.g. follow-up reminders, routing flows).

Both providers are strong technically, with **low-latency streaming**, voice cloning, and multilingual support out of the box.

> Pricing based on public rates as of **May 2025**.

## 8) SIP Trunking â€” Connecting to the Phone Network (Twilio vs Telnyx)

To make and receive real phone calls, we need to connect our voice-AI system to the **PSTN (Public Switched Telephone Network)**. This is where **SIP trunking** comes in. It acts as the bridge between the internet and traditional phone numbers.

In our setup, we evaluated two leading providers:

- **Twilio**
- **Telnyx**

Both integrate seamlessly with **LiveKit**, enabling bi-directional SIP call routing with support for outbound and inbound audio streams.

---

### ğŸ” Understanding the Billing: Origination vs Termination

SIP trunking costs are typically split into:

- **Termination** â€” outbound calls (your AI calls a user)
- **Origination** â€” inbound calls (users call your AI)
- **Phone number rental** â€” flat monthly rate per number

For this analysis, we assume **outbound calling to U.S. local numbers** (the AI initiates the conversation).

---

### ğŸ’° Cost Comparison: Twilio vs Telnyx

| Component         | **Twilio**           | **Telnyx**            |
|-------------------|----------------------|------------------------|
| Termination (outbound) | $0.0011/min         | $0.0050/min             |
| Origination (inbound)  | $0.0034/min         | $0.0035/min             |
| **Total per minute**   | **$0.0045/min**     | **$0.0085/min**         |
| **Cost per 3-min call**| $0.0135             | $0.0255                 |
| **Cost per hour (20 calls)** | $0.27        | $0.51                   |
| **Monthly cost (22,000 calls)** | **$297.00** | **$561.00**           |

> Note: Phone number rental (e.g. $1.15/month for a local number) is a small fixed cost and not included here, since itâ€™s negligible at volume.

---

### ğŸ“Œ Summary

- **Twilio** is more cost-effective at lower scale, with highly transparent pricing.
- **Telnyx** offers flexibility, more control over routing, and competitive rates at higher volumes, especially for international calls.
- Both are easy to integrate with **LiveKit SIP features**, making them suitable choices depending on your cost or feature preferences.

> Pricing based on public SIP trunking rates as of **May 2025**.

## Putting It All Together â€” Full Stack Cost Comparison

Now that weâ€™ve broken down each component, letâ€™s summarize the total cost of running a fully orchestrated voice AI system. We'll compare two realistic deployment stacks:

### ğŸŸ¢ Economy Stack

- **TTS:** Cartesia (Scale plan)
- **SIP Trunking:** Twilio
- **STT:** Deepgram (Nova-2 Enterprise)
- **LLM:** GPT-4.1 mini
- **Audio Orchestration:** LiveKit (Scale plan)

### ğŸ”µ Premium Stack

- **TTS:** ElevenLabs (Business plan + overage)
- **SIP Trunking:** Telnyx
- **STT:** Deepgram (Nova-2 Enterprise)
- **LLM:** GPT-4.1 mini
- **Audio Orchestration:** LiveKit (Scale plan)

---

### ğŸ’µ Cost Comparison Table

| Component       | Economy Stack       | Premium Stack        |
|------------------|---------------------|-----------------------|
| **LiveKit**       | $563.00             | $563.00               |
| **STT (Deepgram)**| $155.10             | $155.10               |
| **LLM (GPT-4.1 mini)** | $42.37        | $42.37                |
| **TTS**           | $986.70 (Cartesia)  | $1,980.00 (11Labs)    |
| **SIP Trunking**  | $297.00 (Twilio)    | $561.00 (Telnyx)      |
| **TOTAL**         | **$2,044.17**       | **$3,301.47**         |

---

### ğŸ§® Unit Economics

| Metric            | Economy Stack | Premium Stack |
|-------------------|---------------|---------------|
| **Per call**      | $0.0929       | $0.1500       |
| **Per hour (20 calls)** | $1.86    | $3.00         |

---

### ğŸ† Which Stack Wins?

The **Economy Stack** clearly offers **substantial savings**, making it a great choice for:

- High-volume, low-complexity workflows
- Prototypes or early-stage deployments
- Use cases where expressive TTS is not critical

Meanwhile, the **Premium Stack** is ideal when:

- Caller experience and vocal quality are top priorities
- You need branded voices or enhanced emotional range
- You're targeting sensitive, trust-critical interactions (e.g., healthcare, finance)

Both stacks are production-ready, but the **Economy Stack costs ~38% less per call**, making it the winner in terms of operational efficiency.

---

### ğŸ“Š Visual Overview - Cost Comparison Bar Chart (Monthly Total and Per Call)

#### Total Monthly Cost (USD)

| Stack          | Cost (USD) |
|----------------|------------|
| Economy Stack  | $2,044     |
| Premium Stack  | $3,301     |

#### Cost Per Call (USD)

| Stack          | Cost Per Call  |
|----------------|----------------|
| Economy Stack  | $0.093         |
| Premium Stack  | $0.150         |

> Note: All prices reflect public rates as of **May 2025**. Each component exceeds the highest pricing tier currently listed, so **enterprise-level negotiation is likely to yield 30â€“50% discounts** when deployed at scale.
> With those discounts, the Economy Stack could drop below **$1,500/month**, and the Premium Stack below **$2,300/month**, making large-scale deployment increasingly feasible.

## 10) Negotiating Beyond Public Pricing Tiers

At the scale weâ€™re modelingâ€”**22,000 calls per month**, totaling **66,000 minutes of voice**, **33,000 minutes of TTS**, and **33,000 minutes of transcription**â€”**every major component of the stack exceeds the highest publicly available pricing tier**.

That includes:

- **LiveKit** (Scale plan: 45,000 min included â†’ we use 66,000)
- **Deepgram** (Enterprise pricing already applies)
- **ElevenLabs** (Business plan includes 22,000 min â†’ we use 33,000)
- **Cartesia** (Scale plan rates exceeded)
- **Twilio / Telnyx** (volume usage beyond typical pay-as-you-go)
- **OpenAI GPT-4.1 mini** (high token volume, consistent monthly usage)

---

### ğŸ§¾ Why Enterprise Negotiation Matters

When your usage becomes predictable and high-volume, vendors are often open to:

- **Committed-use discounts**
- **Volume-based pricing tiers**
- **Bundled service contracts**
- **Custom SLAs and support**

Discounts in the **30%â€“50% range** are realistic, especially when:

- You negotiate multi-month or annual commitments
- You consolidate services under a single provider
- You become a reference customer or provide product feedback

---

### ğŸ’¸ Recalculated Costs with ~40% Discount

Applying a **conservative 40% discount** across the stack:

| Stack Type     | Full Price (Monthly) | After Discount (â€“40%) |
|----------------|-----------------------|------------------------|
| Economy Stack  | $2,044.17             | **$1,226.50**          |
| Premium Stack  | $3,301.47             | **$1,980.88**          |

These adjusted prices bring the **cost per call** down to:

- **Economy Stack:** ~$0.056
- **Premium Stack:** ~$0.090

And **cost per hour** down to:

- **Economy Stack:** ~$1.12
- **Premium Stack:** ~$1.80

---

### âœ… Final Takeaway

If youâ€™re planning to scale voice-AI automation beyond a few thousand calls per month, donâ€™t rely solely on self-serve pricing pages. Reach out to each vendorâ€™s enterprise sales teamâ€”you may unlock significant savings that make production-scale deployment much more cost-effective than it initially appears.

> All cost assumptions based on publicly available pricing as of **May 2025**.

## 11) Operational Tips & Optimizations

Once your voice-AI system is up and running, there are several strategies you can apply to reduce costs, improve performance, and make the whole experience smootherâ€”without sacrificing quality.

Here are some of the most effective optimizations:

---

### ğŸ§  1. Trim the Token Window

Language model input costs scale with conversation history. Instead of sending the full transcript on every turn:

- **Summarize earlier turns** into compact memory chunks.
- **Remove low-value exchanges** like â€œOK,â€ â€œSure,â€ or greetings.
- **Use windowing strategies** (e.g., keep the last 3â€“4 turns only).

This helps reduce input token usage, especially in longer conversations.

---

### ğŸ”‡ 2. Silence Trimming & Voice Activity Detection (VAD)

Avoid processing and transcribing empty audio:

- Use **Voice Activity Detection** to skip long silences or background noise.
- Trim pauses before sending audio to STT or TTS services.
- Detect **barge-ins** (caller interrupts the bot) to pause TTS playback early.

This reduces billed minutes on both STT and TTS sides.

---

### ğŸ§¾ 3. Cache the System Prompt

OpenAI allows **cached input tokens** (like a static system prompt) at a much lower rate. Make sure you:

- Keep your **system prompt constant across requests**.
- Use API options that take advantage of caching when possible.
- Avoid resending unchanged instructions as raw text.

---

### ğŸ’¬ 4. Pre-generate Common Replies

For deterministic workflows (like confirming an appointment or collecting a yes/no), you can:

- Use **pre-written text responses**
- Skip the language model entirely for predictable branches
- Cut latency and token cost to zero on those turns

---

### ğŸ“‰ 5. Committed-Use Agreements

Once your usage stabilizes, talk to each vendor about:

- **Volume discounts**
- **Annual billing options**
- **Custom usage tiers**

Vendors are often willing to negotiate lower prices when you commit to consistent usage or bundle multiple services.

---

### ğŸ› ï¸ Bonus: Monitor & Adapt in Real Time

Use analytics and observability tools (like SIP Insights, LiveKit metrics, or transcription confidence scores) to:

- Spot anomalies (long silences, error spikes, dropped calls)
- Optimize system behavior dynamically
- Choose which interactions need human handoff

---

By applying even a few of these strategies, you can significantly reduce operational costs, improve response times, and deliver a more professional and polished AI voice experience.

## 12) Conclusion â€” When the Numbers Make Sense, and When the Voice Matters

Automating voice workflows isnâ€™t about replacing peopleâ€”it's about taking the repetitive, high-frequency interactions off their plates so they can focus on more meaningful work. With the right architecture and cost controls in place, voice-AI agents can handle thousands of predictable conversations efficiently and affordably.

### ğŸ“Š The Break-Even Point

At roughly **$0.056â€“$0.09 per call** (with enterprise pricing), you can simulate the monthly output of **10 full-time agents** for **$1,200â€“$2,000/month**. Depending on your geography, staffing model, and call volume, thatâ€™s often below the cost of a single human operator.

This makes voice automation compelling for:

- Lead qualification
- Appointment reminders
- Customer surveys
- Payment follow-ups
- Routine inbound routing

Especially when those interactions follow predictable patterns or scripted flows.

---

### ğŸ”¬ Where to Experiment Next

If you're considering deploying your own voice AI assistant, the next logical steps might include:

- Testing real customer calls with different TTS providers
- Measuring drop-off rates and call completion times
- A/B testing voice styles or model temperatures
- Monitoring cost per resolved interaction over time
- Integrating fallback routes for complex queries (human transfer, async follow-up)

Voice automation is no longer experimentalâ€”it's becoming operational. With the right balance of cost, quality, and control, you can build something that not only saves time but feels genuinely helpful to the people on the other end of the line.

## 13) Resources & Links

Hereâ€™s a list of all the official pricing and documentation pages for the tools and platforms referenced throughout this article. You can refer to these for the latest rates, usage limits, and API capabilities:

### ğŸ”· LiveKit

    - [LiveKit Pricing](https://livekit.io/pricing)
    - [LiveKit Docs](https://docs.livekit.io/home/)

### ğŸ”· Deepgram (Speech-to-Text)

    - [Deepgram Pricing](https://deepgram.com/pricing)  
    - [Deepgram API Docs](https://developers.deepgram.com/home/introduction)

### ğŸ”· OpenAI (GPT-4.1 mini)

    - [OpenAI Pricing](https://openai.com/api/pricing/)  
    - [OpenAI API Docs](https://platform.openai.com/docs/overview)

### ğŸ”· ElevenLabs (Text-to-Speech)

    - [ElevenLabs Pricing](https://elevenlabs.io/pricing/api)  
    - [ElevenLabs Docs](https://elevenlabs.io/docs/overview)

### ğŸ”· Cartesia

    - [Cartesia Pricing](https://cartesia.ai/pricing)  
    - [Cartesia API Docs](https://docs.cartesia.ai/2024-11-13/get-started/overview)

### ğŸ”· Twilio (SIP Trunking)

    - [Twilio SIP Pricing](https://www.twilio.com/en-us/sip-trunking/pricing/us)  
    - [Twilio Docs](https://www.twilio.com/docs/sip-trunking)

### ğŸ”· Telnyx (SIP Trunking)

    - [Telnyx SIP Pricing](https://telnyx.com/pricing/elastic-sip)  
    - [Telnyx Docs](https://developers.telnyx.com/)
